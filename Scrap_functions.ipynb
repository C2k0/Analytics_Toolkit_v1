{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latest versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Read in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ref = {\n",
    "    key_id_cols = [],\n",
    "    key_dt_col = null,\n",
    "    dt_cols = [],\n",
    "    numeric_cols = []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, data_source=None):\n",
    "        \"\"\"Initialize the Dataset with an optional data source.\"\"\"\n",
    "\n",
    "        if not data_source or not isinstance(data_source, str) or not data_source.endswith('.csv'):\n",
    "            raise ValueError(\"The data_source must be a valid .csv file\")\n",
    "\n",
    "\n",
    "        self.data_source = data_source  # Source of the data (e.g., file path, database connection)\n",
    "        self.attributes = {}  # Dictionary to store dataset attributes\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"Load data from the data source and populate attributes.\"\"\"\n",
    "        if not self.data_source:\n",
    "            raise ValueError(\"No data source provided\")\n",
    "        \n",
    "        # Example of populating the attributes dictionary\n",
    "        self.attributes['rows'] = self._read_data()\n",
    "        self.attributes['columns'] = self._extract_columns()\n",
    "        self.attributes['data_type'] = self._infer_data_type()\n",
    "        # Add more attributes as needed\n",
    "\n",
    "    def _read_data(self):\n",
    "        \"\"\"\n",
    "        Private method to read data from the data source.\n",
    "        Identifies if data source is file or database (SF)\n",
    "        \"\"\"\n",
    "\n",
    "        if 'csv.' in data_source:\n",
    "            return pd.read_csv(data_source)\n",
    "        \n",
    "        else:\n",
    "            print('Snowflake/SQL support coming later....')\n",
    "            break\n",
    "        \n",
    "        \n",
    "        # Implement logic to read data from self.data_source\n",
    "        # This could be reading from a CSV file, database, etc.\n",
    "        # For this example, let's assume it reads and returns the number of rows\n",
    "        return 1000  # Placeholder value, replace with actual data reading logic\n",
    "\n",
    "    def _extract_columns(self):\n",
    "        \"\"\"Private method to extract columns from the data.\"\"\"\n",
    "        # Implement logic to extract column names or metadata\n",
    "        return ['column1', 'column2', 'column3']  # Placeholder values\n",
    "\n",
    "    def _infer_data_type(self):\n",
    "        \"\"\"Private method to infer the data type of the dataset.\"\"\"\n",
    "        # Implement logic to infer the data type\n",
    "        return 'tabular'  # Placeholder value\n",
    "\n",
    "    def get_attributes(self):\n",
    "        \"\"\"Public method to retrieve the attributes dictionary.\"\"\"\n",
    "        return self.attributes\n",
    "\n",
    "# usage:\n",
    "# dataset = Dataset(data_source='path/to/data.csv')\n",
    "# dataset.load_data()\n",
    "# attributes = dataset.get_attributes()\n",
    "# print(attributes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working/Scrap Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def read_sql_files(directory):\n",
    "    sql_files = []\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith(\".sql\"):\n",
    "            file_path = os.path.join(directory, file)\n",
    "            with open(file_path, \"r\") as f:\n",
    "                sql_files.append(f.read())\n",
    "    return sql_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class Query:\n",
    "    def __init__(self, query_text, dependencies=None):\n",
    "        self.query_text = query_text\n",
    "        self.dependencies = dependencies if dependencies else []\n",
    "\n",
    "    def add_dependency(self, dependency):\n",
    "        self.dependencies.append(dependency)\n",
    "\n",
    "    def performance_measure(self, connector):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Execute the query using the SQL connector\n",
    "        connector.execute(self.query_text)\n",
    "\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "\n",
    "        return execution_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_value(x):\n",
    "    return -x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'read_sql_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/n8/v5xhvrcx6p54yf0gx0hv14qw0000gn/T/ipykernel_47778/792425795.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Read the .sql files and store the contents in a list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msql_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_sql_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Create Query objects for each SQL query\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'read_sql_files' is not defined"
     ]
    }
   ],
   "source": [
    "# Specify the directory containing the .sql files\n",
    "directory = \"path/to/sql/files\"\n",
    "\n",
    "# Read the .sql files and store the contents in a list\n",
    "sql_files = read_sql_files(directory)\n",
    "\n",
    "# Create Query objects for each SQL query\n",
    "queries = []\n",
    "for sql_text in sql_files:\n",
    "    query = Query(sql_text)\n",
    "    queries.append(query)\n",
    "\n",
    "# Print the queries\n",
    "for query in queries:\n",
    "    print(\"Query Text:\", query.query_text)\n",
    "    print(\"Dependencies:\", query.dependencies)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Query object for 'query53'\n",
    "query53 = Query('query53')\n",
    "\n",
    "# Pass the query to the connect function\n",
    "connect(query53)\n",
    "\n",
    "# Measure the performance of query53\n",
    "execution_time = query53.performance_measure(connector)\n",
    "\n",
    "# Print the execution time\n",
    "print(\"Execution time for query53:\", execution_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query recognizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing match....: |table1|\n",
      "{'type1': [], 'type2': ['table1 type2']}\n",
      "printing match....: |table2|\n",
      "{'type1': [], 'type2': ['table2 type2']}\n",
      "{'type1': [], 'type2': []}\n",
      "{'type1': [], 'type2': []}\n",
      "printing match....: |table5|\n",
      "{'type1': [], 'type2': ['table5 type2']}\n",
      "printing match....: |BIG_TABLE75)|\n",
      "{'type1': [], 'type2': ['BIG_TABLE75) type2']}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def list_references(text):\n",
    "    \n",
    "    #identify tables (not CTE's)\n",
    "    matches = re.findall(r'FROM\\s+(.*?)\\s', text, re.IGNORECASE)\n",
    "\n",
    "    result = {'type1': [], 'type2': []}\n",
    "    \n",
    "    for match in matches:\n",
    "        \n",
    "        print(f'printing match....: |{match}|')\n",
    "        if match.startswith('('):\n",
    "            result['type1'].append(match + ' type1')\n",
    "        else:\n",
    "            result['type2'].append(match + ' type2')\n",
    "    \n",
    "    return result\n",
    "\n",
    "sample_queries = [\n",
    "    \"SELECT * FROM table1 t1\",\n",
    "    \"SELECT column1, column2 FROM table2 t2\",\n",
    "    \"SELECT COUNT(*) FROM table3\",\n",
    "    \"SELECT AVG(column1) FROM table4\",\n",
    "    \"SELECT column1, column2 FROM table5 WHERE column3 = 'value'\",\n",
    "    \"WITH cte5 AS (SELECT * FROM BIG_TABLE75) WHERE X=35\"\n",
    "]\n",
    "\n",
    "for s in sample_queries:\n",
    "    print(list_references(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type1': [], 'type2': ['table1 type2']}\n",
      "{'type1': [], 'type2': ['table2 type2']}\n",
      "{'type1': [], 'type2': ['table3 type2']}\n",
      "{'type1': [], 'type2': ['table4 type2']}\n",
      "{'type1': [], 'type2': [\"table5 WHERE column3 = 'value' type2\"]}\n"
     ]
    }
   ],
   "source": [
    "sample_queries = [\n",
    "    \"SELECT * FROM table1\",\n",
    "    \"SELECT column1, column2 FROM table2\",\n",
    "    \"SELECT COUNT(*) FROM table3\",\n",
    "    \"SELECT AVG(column1) FROM table4\",\n",
    "    \"SELECT column1, column2 FROM table5 WHERE column3 = 'value'\"\n",
    "]\n",
    "\n",
    "for s in sample_queries:\n",
    "    print(extract_and_classify(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQL Alchemy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "import os\n",
    "\n",
    "# Specify the directory containing the .sql files\n",
    "directory = \"path/to/sql/files\"\n",
    "\n",
    "# Read the .sql files and store the contents in a list\n",
    "sql_files = []\n",
    "for file in os.listdir(directory):\n",
    "    if file.endswith(\".sql\"):\n",
    "        file_path = os.path.join(directory, file)\n",
    "        with open(file_path, \"r\") as f:\n",
    "            sql_files.append(f.read())\n",
    "\n",
    "# Create a SQLAlchemy engine\n",
    "engine = create_engine(\"your_database_connection_string\")\n",
    "\n",
    "# Execute the SQL queries\n",
    "for sql_text in sql_files:\n",
    "    query = text(sql_text)\n",
    "    result = engine.execute(query)\n",
    "    # Process the query result as needed\n",
    "    for row in result:\n",
    "        print(row)\n",
    "\n",
    "# Close the SQLAlchemy engine\n",
    "engine.dispose()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "71578bdadfa908a3bb77f984a031c0b45911eb57d4903d8014652388580d2f4c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
